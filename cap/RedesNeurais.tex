\chapter{Redes Neurais, yeah.}
%quad = paragrafo \\ pula linha
\quad Hello World !!!
\quad Introdução: de forma geral pode-se dizer que um mapa auto-organizavel é estruturado pelo neurônio vencedor de uma competição ditadada por uma função discriminante de cada iteração, tambem chamada de época. Essa competição pode ser em neuronio contra todos os neuronios da rede, ou, neuronio contra um grupo de neuronio da rede. A idéia principal de um algoritmo auto-organizado é descobrir padrões significativos ou caracteristicas nos dados de entrada e fazer esta descoberta  sem um professor. Para fauxiliar , o algoritmo possui um conjunto de regras de natureza local. O termo “local” significa que a modificação aplicada ao peso sinaptico de um neuronio é confinada a vizinhança imediata daquele neuronio.

\section { ALGUNS PRINCIPIOS INTUITIVOS DE AUTO-ORGANIZAÇÃO}

\quad “Ordem global pode surgir de interações locais”. Turing, 1952..

	A organização da rede acontece em dois niveis diferentes que interagem entre si na forma de um laço de realimentação. Os dois niveis são:
\begin{itemize}
\item  Atividade: Certos padrões de atividade são produzidos pro uma determinada rede em resposta a sinais de entrada.
\item Conectividade: Forças de conexão dos pesos sinápticos da rede, são modificadas em resposta a sinais neurais dos padrões de atividade, devido à plasticidade sináptica que é uma propriedade que permite que materiais sejam deformados sem que haja rachadura ou rompimento. .
\end{itemize}
A seguir os princípios.
\begin{itemize}
\item  Modificaçoes dos pesos  sinapticos tendem a se auto-amplificar.
	Para estabilizar o sistema, deve haver alguma forma de competição por recursos”limitados” . Especificamente, um aumento na força de algumas sinapses da rede deve ser compensados por uma redução em outras sinapses.
\item  A limitação de recursos leva à competição entre sinapses e com isso à seleção das sinapses  que crescem mais vigorosamente(i.e, as mais ajustadas) às custas das outras sinapses.
\item As modificações em pesos sinápticos tendem a cooperar.
\item Ordem e estrutura nos padrões de informação representam informação redundante que é adquirida pela rede neural na forma de conhecimento, que é um pré-requisito necessário para a aprendizagem.
\end{itemize}
\section {Dois modelos básicos de mapemanto de características}
	Usaremos aqui o modelo de KOHONEM, pois ele foi o que mais se mostrou generico, ou seja, além de não possuir tanta enfase na parte biológica, ele se mantém bem flexivel do ponto de vista computacional.

\subsection {Mapa Auto-Organizavel}
\quad Recebe como entrada um padrão de dados discretos, ao quais, é modelodo em forma uni ou bidimensional.
	 Logo após de ocorrer a atribuição de valores dos pesos sinapticos, há três processos que devem ocorrer:
\begin {enumerate}

	\item Competição: Para cada padrão de entrada os neuronios são levadas à competição, dado uma função discriminante. E o neurônio com maior peso particular ao fim da função discriminante é considerado vencedor.
	\item Cooperação: O neurônio vencedor determina a localização espacial de uma vizinhança.
	\item Adpatação Sináptica: permite que os neurônios excitados aumentem seus valores individuais da função discriminante em relação ao padrão de entrada através de ajustes em seus pesos sinapticos .
\end{enumerate}

\section {Resumo do algoritmo SOM de Kohonen}

-Um espaço de entrada continuo de padrões de ativação que são gerados de acordo com uma certa distribuição de probabilidade.
-Uma topologia da grade na forma de uma grade de neuronios, que define um espaço de saida discreto.
-Uma função de vizinhança varivel no tempo, [] que é definida em torno de um neuronio vencedor.
-Um parametro da taxa de aprendizagemm [] que começa em um valor inicial [] e então diminui gradualmente com o  tempo, n, mas nunca vai a zero.
.-1000 iteraçoes, para um mapeamneto satisfatorio.

	Após a inicialização há 3 passos basicos envolvidos.Estes três passos são repetidos até a formação do mapa de caracteristicas estar completa. O algoritmo é resumido como segue: 
1. Inicialização. Escolha valores aleatórios  para os vetores de peso iniciais [], a única restrição aqui é para que os [], sejam diferentes para j= 1..l, onde l é o numero de neurônios na grade. Pode ser desejável manter a magnitude dos pesos pequena.
2. Amostragem: retire uma amostra x do espaço de entrada com uma certa probabilidade; o vetor x representa o padrão de ativação que é aplicado à grade. A dimensão do etor x é igual a m.
3. Casamento por similaridade. Encontre o neurônio com o melhor casamento(vencedor) i(x) no passo de tempo n usando o critério da minima distancia euclidianta[]
4. Atualização. Ajuste vetores e peso sináptico de todos os neurônios usando a formula de atualização []
5. Continuação. Continue com o passo 2 até que não sejam observadas modificações significativos no mapa de caracteristicas.

9.5. PROPRIEDADES DO MAPA DE CARACTERISTICAS.
	Uma vez que o algoritmo SOM tenha convergido, o mapa de caracteristicas calculado pelo algoritmo mostra caracteristicas estatisticas imporntantes do espaço de entrada..
Propriedade 1: Aproximação do Espaço de Entrada.
Propriedade 2:Ordenação Topológica.
Propriedade 3: Casamento de Densidade.
Propriedade 4: Seleção de Caracteristicas.




